<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Creating a Custom Model Serving Runtime :: Deploying Machine Learning Models with Red Hat OpenShift AI</title>
    <link rel="prev" href="section2.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">Deploying Machine Learning Models with Red Hat OpenShift AI</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/rhods-deploy/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header><div class="body">
<div class="nav-container" data-component="rhods-deploy" data-version="1.33">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Deploying Machine Learning Models with Red Hat OpenShift AI</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">Model Serving in Red Hat OpenShift AI</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section1.html">Model Serving Concepts</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section2.html">OpenVINO Model Serving</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="section3.html">Creating a Custom Model Serving Runtime</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Deploying Machine Learning Models with Red Hat OpenShift AI</span>
    <span class="version">1.33</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Deploying Machine Learning Models with Red Hat OpenShift AI</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1.33</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Deploying Machine Learning Models with Red Hat OpenShift AI</a></li>
    <li><a href="index.html">Model Serving in Red Hat OpenShift AI</a></li>
    <li><a href="section3.html">Creating a Custom Model Serving Runtime</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Creating a Custom Model Serving Runtime</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>A model-serving runtime provides integration with a specified model server and the model frameworks that it supports. By default, Red Hat OpenShift AI includes the OpenVINO Model Server runtime. However, if this runtime doesn’t meet your needs (it doesn’t support a particular model framework, for example), you might want to add your own, custom runtimes.</p>
</div>
<div class="paragraph">
<p>As an administrator, you can use the OpenShift AI interface to add and enable custom model-serving runtimes. You can then choose from your enabled runtimes when you create a new model server.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_prerequisite"><a class="anchor" href="#_prerequisite"></a>Prerequisite</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In order to run this exercise, be sure to have handy the model we created in the previous section, that is:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>An s3 bucket with a model in format <strong>onnx</strong></p>
</li>
<li>
<p>A Data Science project with the name <strong>iris-project</strong></p>
</li>
<li>
<p>A data connection to S3 with the name <strong>iris-data-connection</strong></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This exercise will guide you through the broad steps necessary to deploy a custom Serving Runtime in order to serve a model using the Triton Runtime (NVIDIA Triton Inference Server).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>While RHOAI supports the ability to add your own runtime, it does not support the runtimes themselves. Therefore, it is up to you to configure, adjust and maintain your custom runtimes.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_adding_the_custom_runtime"><a class="anchor" href="#_adding_the_custom_runtime"></a>Adding The Custom Runtime</h2>
<div class="sectionbody">
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Log in to RHOAI with a user who is part of the RHOAI admin group</p>
</li>
<li>
<p>Navigate to the Settings menu, then Serving Runtimes</p>
<div class="imageblock">
<div class="content">
<img src="_images/ServingRuntimes.png" alt="Serving Runtimes">
</div>
</div>
</li>
<li>
<p>Click on the Add Serving Runtime button:</p>
<div class="imageblock">
<div class="content">
<img src="_images/add_serving_runtime.png" alt="Add Serving Runtime">
</div>
</div>
</li>
<li>
<p>Click on Start from scratch and in the window that opens up, paste the following YAML:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
metadata:
  name: triton-23.05-20230804
  labels:
    name: triton-23.05-20230804
  annotations:
    maxLoadingConcurrency: "2"
    openshift.io/display-name: "Triton runtime 23.05"
spec:
  supportedModelFormats:
    - name: keras
      version: "2"
      autoSelect: true
    - name: onnx
      version: "1"
      autoSelect: true
    - name: pytorch
      version: "1"
      autoSelect: true
    - name: tensorflow
      version: "1"
      autoSelect: true
    - name: tensorflow
      version: "2"
      autoSelect: true
    - name: tensorrt
      version: "7"
      autoSelect: true

  protocolVersions:
    - grpc-v2
  multiModel: true

  grpcEndpoint: "port:8085"
  grpcDataEndpoint: "port:8001"

  volumes:
    - name: shm
      emptyDir:
        medium: Memory
        sizeLimit: 2Gi
  containers:
    - name: triton
      image: nvcr.io/nvidia/tritonserver:23.05-py3
      command: [/bin/sh]
      args:
        - -c
        - 'mkdir -p /models/_triton_models;
          chmod 777 /models/_triton_models;
          exec tritonserver
          "--model-repository=/models/_triton_models"
          "--model-control-mode=explicit"
          "--strict-model-config=false"
          "--strict-readiness=false"
          "--allow-http=true"
          "--allow-sagemaker=false"
          '
      volumeMounts:
        - name: shm
          mountPath: /dev/shm
      resources:
        requests:
          cpu: 500m
          memory: 1Gi
        limits:
          cpu: "5"
          memory: 1Gi
      livenessProbe:
        # the server is listening only on 127.0.0.1, so an httpGet probe sent
        # from the kublet running on the node cannot connect to the server
        # (not even with the Host header or host field)
        # exec a curl call to have the request originate from localhost in the
        # container
        exec:
          command:
            - curl
            - --fail
            - --silent
            - --show-error
            - --max-time
            - "9"
            - http://localhost:8000/v2/health/live
        initialDelaySeconds: 5
        periodSeconds: 30
        timeoutSeconds: 10
  builtInAdapter:
    serverType: triton
    runtimeManagementPort: 8001
    memBufferBytes: 134217728
    modelLoadingTimeoutMillis: 90000</code></pre>
</div>
</div>
</li>
<li>
<p>After clicking the <strong>Add</strong> button at the bottom of the input area, we are able to see the new Runtime in the list. We can re-order the list as needed (the order chosen here is the order in which the users will see these choices)</p>
<div class="imageblock">
<div class="content">
<img src="_images/runtimes-list.png" alt="Runtimes List">
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_creating_the_model_server"><a class="anchor" href="#_creating_the_model_server"></a>Creating The Model Server</h2>
<div class="sectionbody">
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Using the <strong>iris-project</strong> created in the previous section, scroll to the <strong>Models and model servers</strong> section, and select the <strong>Add server</strong> button</p>
<div class="imageblock">
<div class="content">
<img src="_images/add-custom-model-server.png" alt="Add server">
</div>
</div>
</li>
<li>
<p>Fill up the form as in the following example, notice how <strong>Triton runtime 23.05</strong> is one of the available options for the <strong>Serving runtime</strong> dropdown.</p>
<div class="paragraph">
<p><span class="image"><img src="_images/custom-model-server-form.png" alt="Add model server form"></span></p>
</div>
</li>
<li>
<p>After clicking the <strong>Add</strong> button at the bottom of the form, we are able to see our <strong>iris-custom-server</strong> model server, created with the <strong>Triton runtime 23.05</strong> serving runtime.</p>
<div class="imageblock">
<div class="content">
<img src="_images/custom-runtime.png" alt="Iris custom server">
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_deploy_the_model"><a class="anchor" href="#_deploy_the_model"></a>Deploy The Model</h2>
<div class="sectionbody">
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Use the <strong>Deploy Model</strong> button at the right of the row with the <strong>iris-custom-server</strong> model server</p>
<div class="imageblock">
<div class="content">
<img src="_images/iris-custom-deploy-model.png" alt="Deploy Model">
</div>
</div>
</li>
<li>
<p>Fill up the <strong>Deploy Model</strong> form as in the following example:</p>
<div class="imageblock">
<div class="content">
<img src="_images/iris-custom-deploy-model-form.png" alt="Deploy model form">
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Notice the model name, in this exercise we are naming it <strong>iris-custom-model</strong>, <em>we can&#8217;t use the <strong>iris-model</strong> name anymore</em>.
You can be creative and name it differently, just mind your selection when running the inference service with the APIs.</p>
</div>
</td>
</tr>
</table>
</div>
</li>
<li>
<p>After clicking the <strong>Deploy</strong> button at the bottom of the form, we see the model added to our <strong>Model Server</strong> row, wait for the green checkmark to appear.</p>
<div class="imageblock">
<div class="content">
<img src="_images/triton-server-running.png" alt="Triton server running">
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_test_the_model_with_curl"><a class="anchor" href="#_test_the_model_with_curl"></a>Test The Model With CURL</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Now that the model is ready to use, we can make an inference using the REST API</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Assign the route to an environment variable in your local machine, so that we can use it in our curl commands</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">export IRIS_ROUTE=https://$(oc get routes -n iris-project | grep iris-custom-model | awk '{print $2}')</code></pre>
</div>
</div>
</li>
<li>
<p>Assign an authentication token to an environment variable in your local machine</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">export TOKEN=$(oc whoami -t)</code></pre>
</div>
</div>
</li>
<li>
<p>Request an inference with the REST API</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">curl -H "Authorization: Bearer $TOKEN" $IRIS_ROUTE/v2/models/iris-custom-model/infer -X POST --data '{"inputs" : [{"name" : "X","shape" : [ 1, 4 ],"datatype" : "FP32","data" : [ 3, 4, 3, 2 ]}]}'</code></pre>
</div>
</div>
</li>
<li>
<p>The result received from the inference service looks like the following:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{"model_name":"iris-custom-model__isvc-9cc7f4ebab","model_version":"1","outputs":[{"name":"label","datatype":"INT64","shape":[1,1],"data":[1]},{"name":"scores","datatype":"FP32","shape":[1,3],"data":[4.851966,3.1275778,3.4580243]}]}</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="section2.html">OpenVINO Model Serving</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
